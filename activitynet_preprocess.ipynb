{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelbox annotations Sample Processing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook contains sample code to process ndjson file we get from a Labelbox project (by exporting data) and process annotations into Activitynet required format (required by ActionFormer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Activitynet json format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\\n  \"video1\": {\\n      \"duration_second\": 211.53,\\n      \"duration_frame\": 6337,\\n      \"annotations\": [\\n          {\\n              \"segment\": [\\n                  30.025882995319815,\\n                  205.2318595943838\\n              ],\\n              \"label\": \"Rock climbing\"\\n          }\\n      ],\\n      \"feature_frame\": 6336,\\n      \"fps\": 30.0,\\n      \"rfps\": 29.9579255898\\n  },\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample\n",
    "\"\"\"\n",
    "{\n",
    "  \"video1\": {\n",
    "      \"duration_second\": 211.53,\n",
    "      \"duration_frame\": 6337,\n",
    "      \"annotations\": [\n",
    "          {\n",
    "              \"segment\": [\n",
    "                  30.025882995319815,\n",
    "                  205.2318595943838\n",
    "              ],\n",
    "              \"label\": \"Rock climbing\"\n",
    "          }\n",
    "      ],\n",
    "      \"feature_frame\": 6336,\n",
    "      \"fps\": 30.0,\n",
    "      \"rfps\": 29.9579255898\n",
    "  },\n",
    "  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ndjson\n",
    "import json\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\VS Code Folders\\ActionFormer\\code files\n"
     ]
    }
   ],
   "source": [
    "!cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of the labelbox metadata file\n",
    "META_DATA_PATH = 'Export  project - YOLO incorrect predicted videos 24.6.2025 - 7_15_2025.ndjson'\n",
    "\n",
    "# directory to download the videos\n",
    "VIDEOS_DIRECTORY = r\"videos\"\n",
    "\n",
    "# path of the file to which save the processed annotations\n",
    "ANNOTATIONS_FILE = 'activitynet_annotations.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(VIDEOS_DIRECTORY, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the activities labels to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_to_track = ['crash', 'drift', 'jump']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary to store the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to download the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(video_url, video_name, video_path):\n",
    "    \"\"\"\n",
    "    Downloads a video from the given URL and saves it with the specified name in the videos folder.\n",
    "    \n",
    "    Args:\n",
    "        video_url (str): The URL of the video to be downloaded.\n",
    "        video_name (str): The name of the video file.\n",
    "        videos_folder (str): The path to the folder where the video will be saved.\n",
    "    \"\"\"\n",
    "    if os.path.exists(video_path):\n",
    "        print(f\"Video '{video_path}' already exists. Skipping download.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(video_url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(video_path, 'wb') as file:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    file.write(chunk)\n",
    "            print(f\"Video '{video_name}' downloaded successfully.\")\n",
    "        else:\n",
    "            print(f\"Error downloading video '{video_name}': {response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading video '{video_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (META_DATA_PATH, 'r') as file:\n",
    "    metadata = ndjson.load(file)\n",
    "    for item in metadata:\n",
    "        video_url = item['data_row']['row_data']\n",
    "        video_name = item['data_row']['external_id']\n",
    "        \n",
    "        processed_data[video_name[:-4]] = {}\n",
    "        processed_data[video_name[:-4]]['duration_second'] = item['media_attributes']['frame_count'] / item['media_attributes']['frame_rate']\n",
    "        processed_data[video_name[:-4]]['duration_frame'] = item['media_attributes']['frame_count']\n",
    "        processed_data[video_name[:-4]]['annotations'] = []\n",
    "        \n",
    "        video_path = os.path.join(VIDEOS_DIRECTORY, video_name)\n",
    "        download_video(video_url, video_name, video_path)\n",
    "        \n",
    "        video_frame_rate = item['media_attributes']['frame_rate']\n",
    "\n",
    "        # Get the first (and usually only) project key\n",
    "        project_dict = item.get(\"projects\", {})\n",
    "        project_key = next(iter(project_dict), None)\n",
    "\n",
    "        if project_key is None:\n",
    "            raise ValueError(f\"No project key found for video: {video_name}\")\n",
    "\n",
    "        frames = item[\"projects\"][project_key][\"labels\"][0][\"annotations\"][\"frames\"]\n",
    "        \n",
    "        # Loop through and extract frame numbers\n",
    "        activities = {}\n",
    "        for frame, annotations in frames.items():\n",
    "            frame = int(frame)\n",
    "            classifications = annotations.get(\"classifications\", [])\n",
    "            for classification in classifications:\n",
    "                label_value = classification[\"value\"]\n",
    "                if label_value not in activities_to_track:\n",
    "                    continue\n",
    "                if label_value not in activities:\n",
    "                    activities[label_value] = []\n",
    "                activities[label_value].append(round(frame / video_frame_rate, 2))\n",
    "        \n",
    "        for key, times_array in activities.items():\n",
    "            times_array.sort()\n",
    "            if (len(times_array) % 2) != 0:\n",
    "                print(video_name)\n",
    "            \n",
    "            \n",
    "            for i in range(0, len(times_array), 2):\n",
    "                annotation_item = {}\n",
    "                annotation_item['segment'] = [times_array[i], times_array[i + 1]]\n",
    "                annotation_item['label'] = key\n",
    "                processed_data[video_name[:-4]]['annotations'].append(annotation_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vid_549': {'duration_second': 7.6,\n",
       "  'duration_frame': 190,\n",
       "  'annotations': [{'segment': [1.32, 1.88], 'label': 'jump'}]},\n",
       " 'vid_550': {'duration_second': 6.6,\n",
       "  'duration_frame': 165,\n",
       "  'annotations': [{'segment': [0.56, 4.64], 'label': 'drift'}]},\n",
       " 'vid_551': {'duration_second': 8.88,\n",
       "  'duration_frame': 222,\n",
       "  'annotations': [{'segment': [1.2, 2.4], 'label': 'drift'}]},\n",
       " 'vid_552': {'duration_second': 8.56,\n",
       "  'duration_frame': 214,\n",
       "  'annotations': [{'segment': [0.68, 1.56], 'label': 'drift'},\n",
       "   {'segment': [2.44, 3.28], 'label': 'drift'},\n",
       "   {'segment': [4.16, 5.16], 'label': 'drift'}]},\n",
       " 'vid_553': {'duration_second': 10.56,\n",
       "  'duration_frame': 264,\n",
       "  'annotations': [{'segment': [1.32, 2.48], 'label': 'drift'},\n",
       "   {'segment': [5.76, 6.92], 'label': 'drift'}]},\n",
       " 'vid_556': {'duration_second': 9.32,\n",
       "  'duration_frame': 233,\n",
       "  'annotations': [{'segment': [0.92, 2.08], 'label': 'drift'}]},\n",
       " 'vid_557': {'duration_second': 7.6,\n",
       "  'duration_frame': 190,\n",
       "  'annotations': [{'segment': [1.48, 2.04], 'label': 'jump'},\n",
       "   {'segment': [4.72, 5.4], 'label': 'jump'}]},\n",
       " 'vid_558': {'duration_second': 10.36,\n",
       "  'duration_frame': 259,\n",
       "  'annotations': [{'segment': [0.84, 2.12], 'label': 'drift'},\n",
       "   {'segment': [3.44, 4.72], 'label': 'drift'},\n",
       "   {'segment': [5.64, 7.4], 'label': 'drift'}]},\n",
       " 'vid_559': {'duration_second': 7.64,\n",
       "  'duration_frame': 191,\n",
       "  'annotations': [{'segment': [1.04, 2.08], 'label': 'drift'},\n",
       "   {'segment': [2.68, 4.08], 'label': 'drift'}]},\n",
       " 'vid_560': {'duration_second': 13.32,\n",
       "  'duration_frame': 333,\n",
       "  'annotations': [{'segment': [2.44, 2.92], 'label': 'drift'},\n",
       "   {'segment': [2.92, 4.32], 'label': 'crash'}]},\n",
       " 'vid_585': {'duration_second': 9.72,\n",
       "  'duration_frame': 243,\n",
       "  'annotations': [{'segment': [0.84, 1.84], 'label': 'drift'}]},\n",
       " 'vid_586': {'duration_second': 8.12,\n",
       "  'duration_frame': 203,\n",
       "  'annotations': [{'segment': [1.12, 1.92], 'label': 'drift'},\n",
       "   {'segment': [2.56, 3.32], 'label': 'drift'}]},\n",
       " 'vid_589': {'duration_second': 6.24,\n",
       "  'duration_frame': 156,\n",
       "  'annotations': [{'segment': [1.08, 2.88], 'label': 'drift'}]},\n",
       " 'vid_591': {'duration_second': 9.44,\n",
       "  'duration_frame': 236,\n",
       "  'annotations': [{'segment': [1.68, 1.88], 'label': 'jump'},\n",
       "   {'segment': [2.52, 2.72], 'label': 'jump'}]},\n",
       " 'vid_592': {'duration_second': 5.92,\n",
       "  'duration_frame': 148,\n",
       "  'annotations': [{'segment': [1.08, 1.64], 'label': 'drift'},\n",
       "   {'segment': [2.76, 4.92], 'label': 'drift'}]},\n",
       " 'vid_593': {'duration_second': 12.4,\n",
       "  'duration_frame': 310,\n",
       "  'annotations': [{'segment': [1.16, 2.04], 'label': 'drift'}]},\n",
       " 'vid_594': {'duration_second': 5.16,\n",
       "  'duration_frame': 129,\n",
       "  'annotations': [{'segment': [1.08, 2.2], 'label': 'drift'}]},\n",
       " 'vid_595': {'duration_second': 12.88,\n",
       "  'duration_frame': 322,\n",
       "  'annotations': [{'segment': [5.92, 8.6], 'label': 'drift'},\n",
       "   {'segment': [9.68, 11.0], 'label': 'drift'}]},\n",
       " 'vid_596': {'duration_second': 8.28,\n",
       "  'duration_frame': 207,\n",
       "  'annotations': [{'segment': [2.92, 3.76], 'label': 'drift'}]},\n",
       " 'vid_597': {'duration_second': 9.68,\n",
       "  'duration_frame': 242,\n",
       "  'annotations': [{'segment': [6.36, 7.16], 'label': 'drift'}]},\n",
       " 'vid_598': {'duration_second': 8.6,\n",
       "  'duration_frame': 215,\n",
       "  'annotations': [{'segment': [0.88, 1.8], 'label': 'drift'},\n",
       "   {'segment': [2.44, 3.52], 'label': 'drift'},\n",
       "   {'segment': [4.8, 6.16], 'label': 'drift'}]},\n",
       " 'vid_599': {'duration_second': 6.56,\n",
       "  'duration_frame': 164,\n",
       "  'annotations': [{'segment': [3.16, 4.48], 'label': 'drift'}]},\n",
       " 'vid_600': {'duration_second': 11.76,\n",
       "  'duration_frame': 294,\n",
       "  'annotations': [{'segment': [1.0, 2.2], 'label': 'drift'}]},\n",
       " 'vid_602': {'duration_second': 8.72,\n",
       "  'duration_frame': 218,\n",
       "  'annotations': [{'segment': [1.12, 2.2], 'label': 'drift'}]},\n",
       " 'vid_603': {'duration_second': 5.76,\n",
       "  'duration_frame': 144,\n",
       "  'annotations': [{'segment': [0.96, 2.64], 'label': 'drift'}]},\n",
       " 'vid_604': {'duration_second': 9.04,\n",
       "  'duration_frame': 226,\n",
       "  'annotations': [{'segment': [1.32, 1.6], 'label': 'jump'}]},\n",
       " 'vid_605': {'duration_second': 16.6,\n",
       "  'duration_frame': 415,\n",
       "  'annotations': []},\n",
       " 'vid_606': {'duration_second': 9.32,\n",
       "  'duration_frame': 233,\n",
       "  'annotations': [{'segment': [4.96, 5.6], 'label': 'drift'}]},\n",
       " 'vid_607': {'duration_second': 9.4,\n",
       "  'duration_frame': 235,\n",
       "  'annotations': [{'segment': [1.16, 1.88], 'label': 'drift'},\n",
       "   {'segment': [2.72, 3.44], 'label': 'drift'},\n",
       "   {'segment': [4.92, 5.6], 'label': 'drift'}]},\n",
       " 'vid_608': {'duration_second': 11.44,\n",
       "  'duration_frame': 286,\n",
       "  'annotations': [{'segment': [1.52, 2.32], 'label': 'jump'}]},\n",
       " 'vid_610': {'duration_second': 7.92,\n",
       "  'duration_frame': 198,\n",
       "  'annotations': [{'segment': [1.68, 2.24], 'label': 'jump'}]},\n",
       " 'vid_612': {'duration_second': 12.16,\n",
       "  'duration_frame': 304,\n",
       "  'annotations': []},\n",
       " 'vid_614': {'duration_second': 13.12,\n",
       "  'duration_frame': 328,\n",
       "  'annotations': []},\n",
       " 'vid_615': {'duration_second': 7.48,\n",
       "  'duration_frame': 187,\n",
       "  'annotations': [{'segment': [1.4, 1.88], 'label': 'jump'}]},\n",
       " 'vid_616': {'duration_second': 9.32,\n",
       "  'duration_frame': 233,\n",
       "  'annotations': [{'segment': [5.72, 6.96], 'label': 'drift'}]},\n",
       " 'vid_617': {'duration_second': 6.2, 'duration_frame': 155, 'annotations': []},\n",
       " 'vid_618': {'duration_second': 8.2,\n",
       "  'duration_frame': 205,\n",
       "  'annotations': [{'segment': [1.8, 2.4], 'label': 'jump'}]},\n",
       " 'vid_619': {'duration_second': 7.4,\n",
       "  'duration_frame': 185,\n",
       "  'annotations': [{'segment': [3.24, 5.52], 'label': 'drift'}]},\n",
       " 'vid_620': {'duration_second': 9.48,\n",
       "  'duration_frame': 237,\n",
       "  'annotations': [{'segment': [1.04, 1.96], 'label': 'drift'},\n",
       "   {'segment': [4.68, 5.76], 'label': 'drift'}]},\n",
       " 'vid_621': {'duration_second': 14.56,\n",
       "  'duration_frame': 364,\n",
       "  'annotations': []},\n",
       " 'vid_622': {'duration_second': 8.16,\n",
       "  'duration_frame': 204,\n",
       "  'annotations': [{'segment': [1.68, 2.24], 'label': 'jump'}]},\n",
       " 'vid_623': {'duration_second': 10.68,\n",
       "  'duration_frame': 267,\n",
       "  'annotations': [{'segment': [1.08, 2.12], 'label': 'drift'}]},\n",
       " 'vid_624': {'duration_second': 8.36,\n",
       "  'duration_frame': 209,\n",
       "  'annotations': []},\n",
       " 'vid_625': {'duration_second': 8.52,\n",
       "  'duration_frame': 213,\n",
       "  'annotations': [{'segment': [3.92, 6.04], 'label': 'drift'}]},\n",
       " 'vid_626': {'duration_second': 8.04,\n",
       "  'duration_frame': 201,\n",
       "  'annotations': []},\n",
       " 'vid_627': {'duration_second': 9.68,\n",
       "  'duration_frame': 242,\n",
       "  'annotations': [{'segment': [1.0, 2.04], 'label': 'drift'}]},\n",
       " 'vid_628': {'duration_second': 9.64,\n",
       "  'duration_frame': 241,\n",
       "  'annotations': [{'segment': [0.84, 2.6], 'label': 'drift'},\n",
       "   {'segment': [5.48, 7.4], 'label': 'drift'}]},\n",
       " 'vid_629': {'duration_second': 6.2, 'duration_frame': 155, 'annotations': []},\n",
       " 'vid_630': {'duration_second': 9.32,\n",
       "  'duration_frame': 233,\n",
       "  'annotations': [{'segment': [0.8, 1.56], 'label': 'drift'},\n",
       "   {'segment': [5.16, 6.88], 'label': 'drift'}]},\n",
       " 'vid_631': {'duration_second': 7.84,\n",
       "  'duration_frame': 196,\n",
       "  'annotations': [{'segment': [1.08, 1.32], 'label': 'jump'}]},\n",
       " 'vid_632': {'duration_second': 6.32,\n",
       "  'duration_frame': 158,\n",
       "  'annotations': [{'segment': [0.84, 1.92], 'label': 'drift'},\n",
       "   {'segment': [2.56, 4.04], 'label': 'drift'}]},\n",
       " 'vid_633': {'duration_second': 9.84,\n",
       "  'duration_frame': 246,\n",
       "  'annotations': [{'segment': [1.16, 2.04], 'label': 'drift'},\n",
       "   {'segment': [2.8, 3.68], 'label': 'drift'}]},\n",
       " 'vid_635': {'duration_second': 9.52,\n",
       "  'duration_frame': 238,\n",
       "  'annotations': [{'segment': [1.8, 2.08], 'label': 'jump'},\n",
       "   {'segment': [2.8, 3.0], 'label': 'jump'}]},\n",
       " 'vid_636': {'duration_second': 7.04,\n",
       "  'duration_frame': 176,\n",
       "  'annotations': [{'segment': [0.88, 5.16], 'label': 'drift'}]},\n",
       " 'vid_637': {'duration_second': 11.24,\n",
       "  'duration_frame': 281,\n",
       "  'annotations': []},\n",
       " 'vid_638': {'duration_second': 7.64,\n",
       "  'duration_frame': 191,\n",
       "  'annotations': [{'segment': [1.44, 2.04], 'label': 'jump'}]},\n",
       " 'vid_639': {'duration_second': 5.68,\n",
       "  'duration_frame': 142,\n",
       "  'annotations': []},\n",
       " 'vid_640': {'duration_second': 9.04,\n",
       "  'duration_frame': 226,\n",
       "  'annotations': [{'segment': [1.2, 2.04], 'label': 'drift'},\n",
       "   {'segment': [4.84, 7.0], 'label': 'drift'}]},\n",
       " 'vid_641': {'duration_second': 15.32,\n",
       "  'duration_frame': 383,\n",
       "  'annotations': [{'segment': [8.12, 10.92], 'label': 'drift'}]},\n",
       " 'vid_642': {'duration_second': 9.6,\n",
       "  'duration_frame': 240,\n",
       "  'annotations': [{'segment': [1.0, 3.48], 'label': 'drift'}]},\n",
       " 'vid_643': {'duration_second': 9.64,\n",
       "  'duration_frame': 241,\n",
       "  'annotations': [{'segment': [0.76, 2.4], 'label': 'drift'},\n",
       "   {'segment': [5.52, 7.28], 'label': 'drift'}]},\n",
       " 'vid_644': {'duration_second': 11.04,\n",
       "  'duration_frame': 276,\n",
       "  'annotations': [{'segment': [1.08, 2.16], 'label': 'drift'}]},\n",
       " 'vid_646': {'duration_second': 8.56,\n",
       "  'duration_frame': 214,\n",
       "  'annotations': [{'segment': [0.84, 2.96], 'label': 'drift'}]},\n",
       " 'vid_647': {'duration_second': 5.16,\n",
       "  'duration_frame': 129,\n",
       "  'annotations': [{'segment': [0.68, 1.92], 'label': 'drift'}]},\n",
       " 'vid_648': {'duration_second': 9.56,\n",
       "  'duration_frame': 239,\n",
       "  'annotations': [{'segment': [0.8, 3.4], 'label': 'drift'}]},\n",
       " 'vid_649': {'duration_second': 8.84,\n",
       "  'duration_frame': 221,\n",
       "  'annotations': []},\n",
       " 'vid_650': {'duration_second': 8.92,\n",
       "  'duration_frame': 223,\n",
       "  'annotations': [{'segment': [1.24, 1.56], 'label': 'jump'}]},\n",
       " 'vid_651': {'duration_second': 6.76,\n",
       "  'duration_frame': 169,\n",
       "  'annotations': [{'segment': [2.44, 4.84], 'label': 'drift'}]},\n",
       " 'vid_652': {'duration_second': 8.36,\n",
       "  'duration_frame': 209,\n",
       "  'annotations': []},\n",
       " 'vid_653': {'duration_second': 9.28,\n",
       "  'duration_frame': 232,\n",
       "  'annotations': []},\n",
       " 'vid_654': {'duration_second': 8.16,\n",
       "  'duration_frame': 204,\n",
       "  'annotations': [{'segment': [1.44, 2.0], 'label': 'jump'}]},\n",
       " 'vid_655': {'duration_second': 9.72,\n",
       "  'duration_frame': 243,\n",
       "  'annotations': [{'segment': [1.24, 1.92], 'label': 'drift'},\n",
       "   {'segment': [4.68, 5.32], 'label': 'drift'}]},\n",
       " 'vid_657': {'duration_second': 10.2,\n",
       "  'duration_frame': 255,\n",
       "  'annotations': [{'segment': [0.84, 2.24], 'label': 'drift'},\n",
       "   {'segment': [2.76, 3.28], 'label': 'drift'}]},\n",
       " 'vid_658': {'duration_second': 15.36,\n",
       "  'duration_frame': 384,\n",
       "  'annotations': [{'segment': [9.04, 13.12], 'label': 'drift'}]},\n",
       " 'vid_659': {'duration_second': 7.64,\n",
       "  'duration_frame': 191,\n",
       "  'annotations': [{'segment': [1.64, 2.24], 'label': 'jump'}]},\n",
       " 'vid_660': {'duration_second': 7.08,\n",
       "  'duration_frame': 177,\n",
       "  'annotations': [{'segment': [3.24, 4.48], 'label': 'drift'}]},\n",
       " 'vid_705': {'duration_second': 3.52, 'duration_frame': 88, 'annotations': []},\n",
       " 'vid_706': {'duration_second': 8.16,\n",
       "  'duration_frame': 204,\n",
       "  'annotations': [{'segment': [3.88, 5.68], 'label': 'crash'},\n",
       "   {'segment': [2.48, 3.24], 'label': 'drift'}]},\n",
       " 'vid_718': {'duration_second': 8.96,\n",
       "  'duration_frame': 224,\n",
       "  'annotations': [{'segment': [0.72, 8.28], 'label': 'crash'}]},\n",
       " 'vid_719': {'duration_second': 10.24,\n",
       "  'duration_frame': 256,\n",
       "  'annotations': [{'segment': [4.0, 6.96], 'label': 'crash'},\n",
       "   {'segment': [3.2, 3.88], 'label': 'drift'}]},\n",
       " 'vid_720': {'duration_second': 8.64,\n",
       "  'duration_frame': 216,\n",
       "  'annotations': [{'segment': [6.8, 7.36], 'label': 'crash'}]},\n",
       " 'vid_721': {'duration_second': 8.88,\n",
       "  'duration_frame': 222,\n",
       "  'annotations': [{'segment': [1.52, 5.52], 'label': 'crash'}]},\n",
       " 'vid_722': {'duration_second': 6.4,\n",
       "  'duration_frame': 160,\n",
       "  'annotations': [{'segment': [2.48, 4.08], 'label': 'crash'}]},\n",
       " 'vid_723': {'duration_second': 11.36,\n",
       "  'duration_frame': 284,\n",
       "  'annotations': [{'segment': [0.48, 2.68], 'label': 'drift'},\n",
       "   {'segment': [2.96, 6.76], 'label': 'crash'}]},\n",
       " 'vid_724': {'duration_second': 10.4,\n",
       "  'duration_frame': 260,\n",
       "  'annotations': [{'segment': [3.4, 4.76], 'label': 'drift'},\n",
       "   {'segment': [4.96, 5.84], 'label': 'crash'}]},\n",
       " 'vid_725': {'duration_second': 4.32,\n",
       "  'duration_frame': 108,\n",
       "  'annotations': [{'segment': [0.92, 1.6], 'label': 'drift'},\n",
       "   {'segment': [1.76, 4.32], 'label': 'crash'}]},\n",
       " 'vid_726': {'duration_second': 11.56,\n",
       "  'duration_frame': 289,\n",
       "  'annotations': [{'segment': [2.28, 3.96], 'label': 'drift'},\n",
       "   {'segment': [4.12, 9.44], 'label': 'crash'}]},\n",
       " 'vid_727': {'duration_second': 3.12, 'duration_frame': 78, 'annotations': []},\n",
       " 'vid_702': {'duration_second': 9.44,\n",
       "  'duration_frame': 236,\n",
       "  'annotations': []},\n",
       " 'vid_703': {'duration_second': 6.0,\n",
       "  'duration_frame': 150,\n",
       "  'annotations': [{'segment': [2.36, 5.68], 'label': 'crash'}]},\n",
       " 'vid_704': {'duration_second': 6.56,\n",
       "  'duration_frame': 164,\n",
       "  'annotations': [{'segment': [0.6, 2.28], 'label': 'drift'},\n",
       "   {'segment': [2.32, 4.2], 'label': 'crash'}]},\n",
       " 'vid_712': {'duration_second': 7.88,\n",
       "  'duration_frame': 197,\n",
       "  'annotations': [{'segment': [2.8, 3.24], 'label': 'crash'}]},\n",
       " 'vid_713': {'duration_second': 8.44,\n",
       "  'duration_frame': 211,\n",
       "  'annotations': [{'segment': [4.52, 5.64], 'label': 'crash'},\n",
       "   {'segment': [2.76, 4.48], 'label': 'drift'}]},\n",
       " 'vid_714': {'duration_second': 12.28,\n",
       "  'duration_frame': 307,\n",
       "  'annotations': [{'segment': [0.48, 1.24], 'label': 'drift'},\n",
       "   {'segment': [1.36, 4.2], 'label': 'crash'}]},\n",
       " 'vid_715': {'duration_second': 10.84,\n",
       "  'duration_frame': 271,\n",
       "  'annotations': [{'segment': [3.8, 5.92], 'label': 'crash'},\n",
       "   {'segment': [3.28, 3.84], 'label': 'drift'}]},\n",
       " 'vid_716': {'duration_second': 6.4,\n",
       "  'duration_frame': 160,\n",
       "  'annotations': [{'segment': [1.04, 3.2], 'label': 'crash'}]},\n",
       " 'vid_717': {'duration_second': 8.0,\n",
       "  'duration_frame': 200,\n",
       "  'annotations': [{'segment': [3.16, 7.76], 'label': 'crash'}]},\n",
       " 'vid_728': {'duration_second': 16.44,\n",
       "  'duration_frame': 411,\n",
       "  'annotations': [{'segment': [4.84, 5.64], 'label': 'crash'}]},\n",
       " 'vid_729': {'duration_second': 10.12,\n",
       "  'duration_frame': 253,\n",
       "  'annotations': [{'segment': [4.2, 6.16], 'label': 'drift'},\n",
       "   {'segment': [5.92, 7.8], 'label': 'crash'}]},\n",
       " 'vid_730': {'duration_second': 9.48,\n",
       "  'duration_frame': 237,\n",
       "  'annotations': [{'segment': [4.8, 6.32], 'label': 'crash'}]},\n",
       " 'vid_731': {'duration_second': 8.8,\n",
       "  'duration_frame': 220,\n",
       "  'annotations': [{'segment': [4.44, 5.36], 'label': 'crash'}]},\n",
       " 'vid_732': {'duration_second': 9.84,\n",
       "  'duration_frame': 246,\n",
       "  'annotations': [{'segment': [5.72, 8.64], 'label': 'crash'}]},\n",
       " 'vid_733': {'duration_second': 11.72,\n",
       "  'duration_frame': 293,\n",
       "  'annotations': [{'segment': [5.16, 8.36], 'label': 'crash'}]},\n",
       " 'vid_734': {'duration_second': 11.16,\n",
       "  'duration_frame': 279,\n",
       "  'annotations': [{'segment': [2.16, 11.16], 'label': 'crash'}]},\n",
       " 'vid_735': {'duration_second': 7.68,\n",
       "  'duration_frame': 192,\n",
       "  'annotations': [{'segment': [2.92, 5.68], 'label': 'crash'}]},\n",
       " 'vid_736': {'duration_second': 11.52,\n",
       "  'duration_frame': 288,\n",
       "  'annotations': [{'segment': [5.08, 7.68], 'label': 'crash'},\n",
       "   {'segment': [3.84, 5.0], 'label': 'drift'}]},\n",
       " 'vid_737': {'duration_second': 5.92,\n",
       "  'duration_frame': 148,\n",
       "  'annotations': [{'segment': [1.64, 2.28], 'label': 'drift'},\n",
       "   {'segment': [2.48, 3.88], 'label': 'crash'}]},\n",
       " 'vid_738': {'duration_second': 5.24,\n",
       "  'duration_frame': 131,\n",
       "  'annotations': [{'segment': [0.8, 1.36], 'label': 'drift'}]},\n",
       " 'vid_739': {'duration_second': 6.72,\n",
       "  'duration_frame': 168,\n",
       "  'annotations': [{'segment': [1.12, 3.56], 'label': 'crash'}]},\n",
       " 'vid_740': {'duration_second': 4.56,\n",
       "  'duration_frame': 114,\n",
       "  'annotations': [{'segment': [0.44, 1.52], 'label': 'drift'},\n",
       "   {'segment': [0.96, 3.2], 'label': 'crash'}]},\n",
       " 'vid_741': {'duration_second': 8.16,\n",
       "  'duration_frame': 204,\n",
       "  'annotations': [{'segment': [3.24, 4.6], 'label': 'crash'}]},\n",
       " 'vid_742': {'duration_second': 20.04,\n",
       "  'duration_frame': 501,\n",
       "  'annotations': [{'segment': [1.12, 3.32], 'label': 'crash'},\n",
       "   {'segment': [11.4, 18.88], 'label': 'crash'},\n",
       "   {'segment': [9.96, 11.24], 'label': 'drift'}]},\n",
       " 'vid_743': {'duration_second': 8.72,\n",
       "  'duration_frame': 218,\n",
       "  'annotations': [{'segment': [3.32, 3.88], 'label': 'drift'},\n",
       "   {'segment': [4.52, 5.24], 'label': 'crash'}]},\n",
       " 'vid_744': {'duration_second': 10.24,\n",
       "  'duration_frame': 256,\n",
       "  'annotations': [{'segment': [2.0, 4.68], 'label': 'drift'},\n",
       "   {'segment': [4.72, 7.36], 'label': 'crash'}]},\n",
       " 'vid_745': {'duration_second': 17.12,\n",
       "  'duration_frame': 428,\n",
       "  'annotations': [{'segment': [1.68, 3.96], 'label': 'crash'}]},\n",
       " 'vid_746': {'duration_second': 13.96,\n",
       "  'duration_frame': 349,\n",
       "  'annotations': [{'segment': [5.76, 7.0], 'label': 'crash'},\n",
       "   {'segment': [4.6, 5.72], 'label': 'drift'}]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the processed annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load existing JSON data if file exists, otherwise start with empty dict\n",
    "try:\n",
    "    with open(ANNOTATIONS_FILE, 'r') as file:\n",
    "        existing_data = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    existing_data = {}\n",
    "\n",
    "# Step 2: Update existing data with new annotations\n",
    "existing_data.update(processed_data)\n",
    "\n",
    "# Step 3: Save back the updated data (create or overwrite file)\n",
    "with open(ANNOTATIONS_FILE, 'w') as file:\n",
    "    json.dump(existing_data, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
